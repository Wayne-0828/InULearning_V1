#!/usr/bin/env python3
"""
å®Œæ•´å­¸ç¿’æµç¨‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ï¼šå‡ºé¡Œ â†’ ç­”é¡Œ â†’ æ‰¹æ”¹ â†’ è¨˜éŒ„å„²å­˜
"""

import asyncio
import httpx
import json
import uuid
from datetime import datetime

# æ¸¬è©¦ç”¨æˆ¶ä¿¡æ¯ (ä½¿ç”¨ä¹‹å‰å‰µå»ºçš„æ¸¬è©¦ç”¨æˆ¶)
TEST_USER = {
    "username": "student01",
    "password": "password123"
}

async def login_user():
    """ç”¨æˆ¶ç™»å…¥ç²å–JWT token"""
    print("ğŸ” ç”¨æˆ¶ç™»å…¥...")
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                "http://localhost/api/v1/auth/login",
                json={
                    "username": TEST_USER["username"],
                    "password": TEST_USER["password"]
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                token = data.get("access_token")
                print(f"âœ… ç™»å…¥æˆåŠŸï¼Œç²å¾—token: {token[:20]}...")
                return token
            else:
                print(f"âŒ ç™»å…¥å¤±æ•—: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ ç™»å…¥éŒ¯èª¤: {e}")
            return None

async def test_question_retrieval():
    """æ¸¬è©¦é¡Œç›®ç²å–ï¼ˆæ¨¡æ“¬å­¸ç¿’æœå‹™çš„é¡Œåº«èª¿ç”¨ï¼‰"""
    print("\nğŸ“š æ¸¬è©¦é¡Œç›®ç²å–...")
    
    async with httpx.AsyncClient() as client:
        try:
            # æ¸¬è©¦æœç´¢APIï¼ˆæ¨¡æ“¬å­¸ç¿’æœå‹™çš„èª¿ç”¨ï¼‰
            response = await client.get(
                "http://localhost:8002/api/v1/questions/search",
                params={
                    "subject": "æ•¸å­¸",
                    "grade": "7A", 
                    "limit": 5
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                questions = data.get("items", [])
                print(f"âœ… æˆåŠŸç²å– {len(questions)} é“é¡Œç›®")
                
                if questions:
                    print("ğŸ“‹ é¡Œç›®ç¤ºä¾‹:")
                    for i, q in enumerate(questions[:2]):
                        print(f"   {i+1}. {q.get('question', 'N/A')[:50]}...")
                        options = q.get('options', {})
                        if isinstance(options, dict):
                            print(f"      é¸é …: {list(options.keys())}")
                        else:
                            print(f"      é¸é …: {type(options)} - {options}")
                        print(f"      æ­£ç¢ºç­”æ¡ˆ: {q.get('answer', 'N/A')}")
                
                return questions
            else:
                print(f"âŒ ç²å–é¡Œç›®å¤±æ•—: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ é¡Œç›®ç²å–éŒ¯èª¤: {e}")
            return []

async def test_auto_grading(questions):
    """æ¸¬è©¦è‡ªå‹•æ‰¹æ”¹åŠŸèƒ½ï¼ˆæ¨¡æ“¬ï¼‰"""
    print("\nğŸ¤– æ¸¬è©¦è‡ªå‹•æ‰¹æ”¹åŠŸèƒ½...")
    
    if not questions:
        print("âŒ æ²’æœ‰é¡Œç›®å¯ä¾›æ¸¬è©¦")
        return []
    
    # æ¨¡æ“¬å­¸ç”Ÿç­”é¡Œ
    student_answers = []
    grading_results = []
    
    for i, question in enumerate(questions[:3]):  # åªæ¸¬è©¦å‰3é“é¡Œ
        question_id = question.get("id")
        correct_answer = question.get("answer")
        
        # æ¨¡æ“¬å­¸ç”Ÿç­”æ¡ˆï¼ˆå‰2é“ç­”å°ï¼Œç¬¬3é“ç­”éŒ¯ï¼‰
        if i < 2:
            student_answer = correct_answer  # ç­”å°
        else:
            # ç­”éŒ¯ï¼šå¦‚æœæ­£ç¢ºç­”æ¡ˆæ˜¯Aï¼Œå­¸ç”Ÿç­”B
            wrong_answers = {"A": "B", "B": "C", "C": "D", "D": "A"}
            student_answer = wrong_answers.get(correct_answer, "B")
        
        student_answers.append({
            "question_id": question_id,
            "user_answer": student_answer,
            "time_spent": 30 + i * 10  # æ¨¡æ“¬ç­”é¡Œæ™‚é–“
        })
        
        # æ¨¡æ“¬è‡ªå‹•æ‰¹æ”¹
        is_correct = student_answer == correct_answer
        score = 10 if is_correct else 0
        
        result = {
            "question_id": question_id,
            "user_answer": student_answer,
            "correct_answer": correct_answer,
            "is_correct": is_correct,
            "score": score,
            "feedback": "ç­”æ¡ˆæ­£ç¢ºï¼è§£é¡Œæ­¥é©Ÿæ¸…æ¥šã€‚" if is_correct else "ç­”æ¡ˆéŒ¯èª¤ï¼Œè«‹é‡æ–°æª¢è¦–è§£é¡Œæ­¥é©Ÿã€‚",
            "explanation": f"é€™é“é¡Œçš„æ­£ç¢ºç­”æ¡ˆæ˜¯ {correct_answer}ã€‚"
        }
        
        grading_results.append(result)
        
        print(f"   é¡Œç›® {i+1}: å­¸ç”Ÿç­”æ¡ˆ {student_answer} | æ­£ç¢ºç­”æ¡ˆ {correct_answer} | {'âœ… æ­£ç¢º' if is_correct else 'âŒ éŒ¯èª¤'} | å¾—åˆ†: {score}")
    
    # è¨ˆç®—ç¸½åˆ†å’Œæ­£ç¢ºç‡
    total_score = sum(r["score"] for r in grading_results)
    correct_count = sum(1 for r in grading_results if r["is_correct"])
    accuracy_rate = correct_count / len(grading_results) * 100
    
    print(f"\nğŸ“Š æ‰¹æ”¹çµæœçµ±è¨ˆ:")
    print(f"   ç¸½åˆ†: {total_score}/{len(grading_results) * 10}")
    print(f"   æ­£ç¢ºç‡: {accuracy_rate:.1f}% ({correct_count}/{len(grading_results)})")
    
    return {
        "answers": student_answers,
        "results": grading_results,
        "total_score": total_score,
        "accuracy_rate": accuracy_rate
    }

async def test_record_storage(grading_data):
    """æ¸¬è©¦è¨˜éŒ„å„²å­˜åŠŸèƒ½ï¼ˆæ¨¡æ“¬ï¼‰"""
    print("\nğŸ’¾ æ¸¬è©¦è¨˜éŒ„å„²å­˜åŠŸèƒ½...")
    
    if not grading_data:
        print("âŒ æ²’æœ‰æ‰¹æ”¹æ•¸æ“šå¯ä¾›å„²å­˜")
        return
    
    # æ¨¡æ“¬å­¸ç¿’è¨˜éŒ„æ•¸æ“šçµæ§‹
    session_id = str(uuid.uuid4())
    learning_session = {
        "id": session_id,
        "user_id": "test-user-uuid",  # æ¨¡æ“¬ç”¨æˆ¶ID
        "session_type": "practice",
        "grade": "7A",
        "subject": "æ•¸å­¸",
        "publisher": "åº·è»’",
        "question_count": len(grading_data["results"]),
        "start_time": datetime.utcnow().isoformat(),
        "end_time": datetime.utcnow().isoformat(),
        "status": "completed",
        "overall_score": grading_data["total_score"],
        "time_spent": sum(a.get("time_spent", 0) for a in grading_data["answers"])
    }
    
    learning_records = []
    for answer, result in zip(grading_data["answers"], grading_data["results"]):
        record = {
            "session_id": session_id,
            "question_id": result["question_id"],
            "grade": "7A",
            "subject": "æ•¸å­¸",
            "publisher": "åº·è»’",
            "chapter": "ä»£æ•¸",  # æ¨¡æ“¬ç« ç¯€
            "difficulty": "normal",
            "user_answer": result["user_answer"],
            "correct_answer": result["correct_answer"],
            "is_correct": result["is_correct"],
            "score": result["score"],
            "time_spent": answer.get("time_spent", 0)
        }
        learning_records.append(record)
    
    print("âœ… å­¸ç¿’æœƒè©±è¨˜éŒ„:")
    print(f"   æœƒè©±ID: {session_id}")
    print(f"   ç¸½åˆ†: {learning_session['overall_score']}")
    print(f"   ç”¨æ™‚: {learning_session['time_spent']} ç§’")
    
    print("âœ… è©³ç´°ç­”é¡Œè¨˜éŒ„:")
    for i, record in enumerate(learning_records):
        print(f"   è¨˜éŒ„ {i+1}: {record['question_id'][:8]}... | {record['user_answer']} | {'âœ“' if record['is_correct'] else 'âœ—'} | {record['score']}åˆ†")
    
    print(f"âœ… æˆåŠŸæ¨¡æ“¬å„²å­˜ {len(learning_records)} æ¢å­¸ç¿’è¨˜éŒ„")
    
    return {
        "session": learning_session,
        "records": learning_records
    }

async def test_complete_learning_flow():
    """æ¸¬è©¦å®Œæ•´å­¸ç¿’æµç¨‹"""
    print("ğŸš€ é–‹å§‹å®Œæ•´å­¸ç¿’æµç¨‹æ¸¬è©¦")
    print("=" * 60)
    
    # 1. ç”¨æˆ¶ç™»å…¥ (æš«æ™‚è·³éï¼Œå°ˆæ³¨æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½)
    print("ğŸ” è·³éç”¨æˆ¶ç™»å…¥ï¼Œå°ˆæ³¨æ¸¬è©¦æ ¸å¿ƒå­¸ç¿’åŠŸèƒ½...")
    token = "mock-token"
    
    # 2. ç²å–é¡Œç›®
    questions = await test_question_retrieval()
    if not questions:
        print("âŒ ç„¡æ³•ç¹¼çºŒæ¸¬è©¦ï¼Œç²å–é¡Œç›®å¤±æ•—")
        return
    
    # 3. è‡ªå‹•æ‰¹æ”¹
    grading_data = await test_auto_grading(questions)
    if not grading_data:
        print("âŒ ç„¡æ³•ç¹¼çºŒæ¸¬è©¦ï¼Œæ‰¹æ”¹å¤±æ•—")
        return
    
    # 4. è¨˜éŒ„å„²å­˜
    storage_data = await test_record_storage(grading_data)
    if not storage_data:
        print("âŒ è¨˜éŒ„å„²å­˜å¤±æ•—")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å®Œæ•´å­¸ç¿’æµç¨‹æ¸¬è©¦å®Œæˆï¼")
    print("\nğŸ“ˆ æ¸¬è©¦çµæœç¸½çµ:")
    print(f"   âš ï¸  ç”¨æˆ¶èªè­‰: è·³éï¼ˆå°ˆæ³¨æ ¸å¿ƒåŠŸèƒ½ï¼‰")
    print(f"   âœ… é¡Œç›®ç²å–: {len(questions)} é“é¡Œç›®")
    print(f"   âœ… è‡ªå‹•æ‰¹æ”¹: {len(grading_data['results'])} é“é¡Œç›®")
    print(f"   âœ… è¨˜éŒ„å„²å­˜: {len(storage_data['records'])} æ¢è¨˜éŒ„")
    print(f"   ğŸ“Š å­¸ç¿’æˆç¸¾: {grading_data['total_score']}/{len(grading_data['results']) * 10} åˆ† ({grading_data['accuracy_rate']:.1f}%)")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    await test_complete_learning_flow()

if __name__ == "__main__":
    asyncio.run(main()) 